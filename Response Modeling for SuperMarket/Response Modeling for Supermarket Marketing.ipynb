{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the daata for project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('marketing_campaign.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Display option to ensure feature name visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning Supperssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since Id feature wont be usefull to train our model.So dropping Id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Target and Independent Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Response'],axis =1)\n",
    "y= df[['Response']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Response Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Lets start Exploring the Independent Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are two columns with year_birth and dt_customer with dates values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer age and Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "reference_date  = datetime.datetime(2022,1,1)\n",
    "print(reference_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Year_Birth'] = pd.to_datetime(df['Year_Birth'],format = '%Y')\n",
    "x['Age'] = (reference_date-x['Year_Birth']).astype('timedelta64[Y]')\n",
    "x['Age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Dt_Customer'] = pd.to_datetime(x['Dt_Customer'])\n",
    "x['Customer_Tenure'] = (reference_date-x['Dt_Customer']).astype('timedelta64[Y]')\n",
    "x['Customer_Tenure'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get the age and customer tenure.So we can drop year_birth and dt_customer columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.drop(['Year_Birth','Dt_Customer'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Features into Numerical and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num = x.select_dtypes(include= 'number')\n",
    "x_char = x.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of Numerical Columns is ',x_num.shape)\n",
    "print('The shape of Categorical Columns is',x_char.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values(x):\n",
    "    x=x.value_counts().count()\n",
    "    return(x)\n",
    "df_value_counts = pd.DataFrame(x_num.apply(lambda x: unique_values(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts.columns = ['feature_Counts']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So here we can see some columns with less unique values.These can considered to be categorical for practile purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let establish the threshold \n",
    "\n",
    "slice1 =df_value_counts.loc[df_value_counts['feature_Counts']<= 20]\n",
    "cat_list=slice1.index\n",
    "cat  =x_num.loc[:,cat_list]\n",
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type_conv(x):\n",
    "    x=x.astype('object')\n",
    "    return(x)\n",
    "cat = cat.apply(lambda x:data_type_conv(x))\n",
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice2 = df_value_counts.loc[df_value_counts['feature_Counts']>20]\n",
    "num_list = slice2.index\n",
    "x_num =x_num.loc[:,num_list]\n",
    "x_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_char = pd.concat([x_char,cat],axis=1,join= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The new shape of numerical columns is',x_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The new Shape of Categorical columns is',x_char.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num.describe(percentiles= [0.01,0.05,0.10,0.15,0.25,0.50,0.75,0.85,0.90,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capping and Flooring of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(x):\n",
    "    x = x.clip(lower= x.quantile(0.01))\n",
    "    x = x.clip(upper = x.quantile(0.99))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num = x_num.apply(lambda x: outlier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num.describe(percentiles= [0.01,0.05,0.10,0.15,0.25,0.50,0.75,0.85,0.90,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Handling - Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values= np.nan,strategy ='mean')\n",
    "x_num1 = pd.DataFrame(imputer.fit_transform(x_num),index = x_num.index,columns=x_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num1.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Handling - Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_char.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection-Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Remove Features with 0 Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "vt = VarianceThreshold(threshold = 0)\n",
    "\n",
    "vt.fit_transform(x_num1)\n",
    "cols = vt.get_support(indices = True)\n",
    "x_num2 = x_num1.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Bi Variate Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discrete = KBinsDiscretizer(n_bins= 10,encode= 'ordinal',strategy ='quantile')\n",
    "x_num_bin = pd.DataFrame(discrete.fit_transform(x_num2),index = x_num2.index,columns = x_num2.columns).add_suffix('_rank')\n",
    "x_num_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bin_combined = pd.concat([y,x_num_bin],axis = 1,join='inner')\n",
    "x_bin_combined=x_bin_combined.astype(int)\n",
    "x_bin_combined.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bin_comdined = x_bin_combined.astype(int)\n",
    "from numpy import mean\n",
    "for col in (x_num_bin.columns):\n",
    "    plt.figure()\n",
    "    sns.lineplot(x=col,y=x_bin_combined['Response'].mean(),data = x_bin_combined,color = 'red')\n",
    "    sns.barplot(x=col,y='Response',data = x_bin_combined,estimator = mean)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num2  = x_num2.drop(['Age'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "selector = SelectKBest(chi2,k=6)\n",
    "selector.fit_transform(x_num2,y)\n",
    "cols = selector.get_support(indices = True)\n",
    "select_features_df_num  = x_num1.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_df_num "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_unique_count = pd.DataFrame(x_char.apply(lambda x: unique_values(x)))\n",
    "char_unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_unique_count.columns = ['feature_levels']\n",
    "slice1 = char_unique_count.loc[char_unique_count['feature_levels']>1]\n",
    "cat_list  = slice1.index\n",
    "x_char = x_char.loc[:,cat_list]\n",
    "x_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_char_merged= pd.concat([y,x_char],axis =1,join = 'inner')\n",
    "from numpy import mean\n",
    "for col in (x_char.columns):\n",
    "    plt.figure()\n",
    "    sns.lineplot(x=col,y=x_char_merged['Response'].mean(),data = x_char_merged,color = 'red')\n",
    "    sns.barplot(x=col,y='Response',data = x_char_merged,estimator = mean)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dropping complain cloumn\n",
    "x_char = x_char.drop(['Complain'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy Features with n-1 levels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_char_dum = pd.get_dummies(x_char,drop_first = True)\n",
    "x_char_dum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "selector = SelectKBest(chi2,k=85)\n",
    "selector.fit_transform(x_char_dum,y)\n",
    "#get columns to keep and create new dataframe with these only\n",
    "cols = selector.get_support(indices = True)\n",
    "select_features_df_char = x_char_dum.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_df_char.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creting the master feature set for model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.concat([select_features_df_char,select_features_df_num ],axis = 1,join ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dimensionality Reduction throug Variable Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from varclushi import VarClusHi\n",
    "vc= VarClusHi(x_all,maxeigval2=1,maxclus = None)\n",
    "vc.varclus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check =vc.rsquare\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter =check[check['RS_Ratio']<= 0.5]\n",
    "filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = filter['Variable']\n",
    "x_all = x_all[final_features]\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test  = train_test_split(x_all,y,test_size = 0.3,random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Training Data',x_train.shape)\n",
    "print('Shape of Testing Data',x_test.shape)\n",
    "print('Shape of response Training Data',y_train.shape)\n",
    "print('Shape of response Testing Data',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion = 'gini',random_state =20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dist = {'max_depth':[3,4,5,6],'min_samples_split':[50,100,125,150]}\n",
    "tree_grid = GridSearchCV(dtree,cv = 10,param_grid= param_dist,n_jobs =-1)\n",
    "tree_grid.fit(x_train,y_train)\n",
    "print('Best parameters using grid search: \\n',tree_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion = 'gini',max_depth=3,min_samples_split= 50,random_state =20)\n",
    "dtree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion ='gini',max_depth = 3,min_samples_split = 50,random_state =20)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier(criterion = 'mse',random_state = 20,max_depth = 3,min_samples_split = 50)\n",
    "gbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logre= logreg.predict(x_test)\n",
    "y_pred_tree = dtree.predict(x_test)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "y_pred_gbm = gbm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy from Logistic Regression Mode:',metrics.accuracy_score(y_test,y_pred_logre))\n",
    "print('Precision from Logistic Regression Model:',metrics.precision_score(y_test,y_pred_logre))\n",
    "print('Recall from Logistic Regression Model:',metrics.recall_score(y_test,y_pred_logre))\n",
    "print('f1_score from Logistic Regression Model:',metrics.f1_score(y_test,y_pred_logre))\n",
    "print('Area under ROC Curve from Logistic Regression Model:',metrics.roc_auc_score(y_test,y_pred_logre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(logreg,x_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy from Decision Tree  Mode:',metrics.accuracy_score(y_test,y_pred_tree))\n",
    "print('Precision from  Decision Tree Model:',metrics.precision_score(y_test,y_pred_tree))\n",
    "print('Recall from Decision Tree Model:',metrics.recall_score(y_test,y_pred_tree))\n",
    "print('f1_score from Decision Tree Model:',metrics.f1_score(y_test,y_pred_tree))\n",
    "print('Area under ROC Curve from Decision Tree Model:',metrics.roc_auc_score(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(dtree,x_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy from Random forest Model:',metrics.accuracy_score(y_test,y_pred_rf))\n",
    "print('Precision from  Random forest Model:',metrics.precision_score(y_test,y_pred_rf))\n",
    "print('Recall from Random forest Model:',metrics.recall_score(y_test,y_pred_rf))\n",
    "print('f1_score from Random forest Model:',metrics.f1_score(y_test,y_pred_rf))\n",
    "print('Area under ROC Curve from Random forest Model:',metrics.roc_auc_score(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(rf,x_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy from Gradient Boosting Model:',metrics.accuracy_score(y_test,y_pred_gbm))\n",
    "print('Precision from  Gradient Boosting Model:',metrics.precision_score(y_test,y_pred_gbm))\n",
    "print('Recall from Gradient Boosting Model:',metrics.recall_score(y_test,y_pred_gbm))\n",
    "print('f1_score from Gradient Boosting Model:',metrics.f1_score(y_test,y_pred_gbm))\n",
    "print('Area under ROC Curve from Gradient Boosting Model:',metrics.roc_auc_score(y_test,y_pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(gbm,x_all,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Feature Importance from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(gbm.feature_importances_,\n",
    "                                  index =x_train.columns,\n",
    "                                  columns= ['importance']).sort_values('importance',ascending = False)\n",
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Top 10 important model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the top 10 feature importance in a Horizontal Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barp = sns.barplot(x='importance',y= feature_importances.iloc[0:10].index,data=feature_importances.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Decile Analysis and Gains Chart/Lorenz Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Getting the Model Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = gbm.predict_proba(x_all)[:,1]\n",
    "df['pred_prob'] = pd.DataFrame(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Create Deciles based on the model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P_Rank_gbm'] = pd.qcut(df['pred_prob'].rank(method ='first').values,10,duplicates = 'drop').codes+1\n",
    "df[['pred_prob','P_Rank_gbm']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-  Summarize the data at decile Level for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = df.groupby('P_Rank_gbm')['Response'].agg(['count','mean']).sort_values(by = 'P_Rank_gbm',ascending =False)\n",
    "rank_df.rename(columns = {'mean':'Actual_event_rate'},inplace =True)\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Event Capture Analysis across probabilities Deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df['N_events'] = rank_df['count']*rank_df['Actual_event_rate']\n",
    "rank_df['cum_events'] = rank_df['N_events'].cumsum()\n",
    "rank_df['event_cap'] = rank_df['N_events']/max(rank_df['N_events'].cumsum())\n",
    "rank_df['cum_event_cap'] = rank_df['event_cap'].cumsum()\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Non event Capture Analysis across Probability Deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df['N_non_events']  = rank_df['count']- rank_df['N_events']\n",
    "rank_df['cum_non_events'] = rank_df['N_non_events'].cumsum()\n",
    "rank_df['non_event_cap'] = rank_df['N_non_events']/max(rank_df['N_non_events'].cumsum())\n",
    "rank_df['cum_non_event_cap'] = rank_df['non_event_cap'].cumsum()\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Compute KS Statistic and lift over Baseline Event Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df['KS'] = round((rank_df['cum_event_cap'] - rank_df['cum_non_event_cap']),4)\n",
    "rank_df['Baseline_Event_Rate'] = (max(rank_df['cum_events'])/max(rank_df['count'].cumsum()))\n",
    "rank_df['Lift_over_avg'] = rank_df['Actual_event_rate']/rank_df['Baseline_Event_Rate']\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Create Deciles(1-10) column to indicate the Decile Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df= rank_df.reset_index()\n",
    "rank_df['Decile'] = rank_df.index+1\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization the performance of model probabilities across deciles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Create the rank ordering chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=\"Decile\", y=\"Actual_event_rate\", data=rank_df,color='green').set_title('Rank Ordering Chart')\n",
    "ax = sns.scatterplot( x=\"Decile\", y=\"Baseline_Event_Rate\", data=rank_df,color='red')\n",
    "ax.legend(['Actual_event_rate', 'Baseline_Event_Rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9- Create the lift chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot( x=\"Decile\", y=\"Lift_over_avg\", data=rank_df,color='blue').set_title('Lift Chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10- Create the Gains Chart/ Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"cum_event_cap\", data=rank_df,color='red').set_title('Rank Ordering Chart')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"cum_non_event_cap\", data=rank_df,color='green')\n",
    "ax.legend(['cum_event_cap', 'cum_non_event_cap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is our model able to maximise event/non-event discrimination by the top 3 deciles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot( x=\"Decile\", y=\"KS\", data=rank_df,color='brown')\n",
    "ax.legend(['KS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utlize APT framework to build a Machine Learning Driven Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - Audience (Who do we traget?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Predicted_Resp_Rank'] = np.where(df['P_Rank_gbm']>=9,'Top 2','Bottom 8')\n",
    "df['Predicted_Resp_Rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top2 = df.loc[df['Predicted_Resp_Rank'] == 'Top 2',:]\n",
    "df_top2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P - Prioritization (Based on Bussiness Value and Customer Engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top2['spend_count'] = np.count_nonzero(df_top2[['MntMeatProducts','MntWines','MntFruits','MntFishProducts','MntSweetProducts','MntGoldProds']],axis =1)\n",
    "df_top2['spend_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top2['Engagement'] = np.where(df_top2['spend_count']< df_top2['spend_count'].quantile(0.75),'Low','High')\n",
    "df_top2['Engagement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top2['Total_Spend']=df_top2['MntWines']+df_top2['MntFruits']+df_top2['MntMeatProducts']+df_top2['MntFishProducts']+df_top2['MntSweetProducts']+df_top2['MntGoldProds']\n",
    "df_top2['Total_Spend'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top2['spend_level']=np.where(df_top2['Total_Spend']<df_top2['Total_Spend'].quantile(0.75),\"Low Spend\",\"High Spend\")\n",
    "df_top2['spend_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df_top2['spend_level'], columns=df_top2['Engagement'],values=df_top2['Response'],aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df_top2['spend_level'], columns=df_top2['Engagement'],values=df_top2['Response'],aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_priority_1=df_top2.loc[(df_top2['spend_level']=='High Spend') & (df_top2['Engagement']=='Low'),:]\n",
    "df_priority_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_priority_2=df_top2.loc[(df_top2['spend_level']=='High Spend') & (df_top2['Engagement']=='High'),:]\n",
    "df_priority_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_priority_3=df_top2.loc[(df_top2['spend_level']=='Low Spend') & (df_top2['Engagement']=='High'),:]\n",
    "df_priority_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_priority_4=df_top2.loc[(df_top2['spend_level']=='Low Spend') & (df_top2['Engagement']=='Low'),:]\n",
    "df_priority_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T - Treatment(Identify Service/Product Preferences of each Priority Segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_cat_priority1=df_priority_1[['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_avg = spend_cat_priority1.mean(axis=0).sort_values(ascending=False)\n",
    "spend_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_cat_priority2=df_priority_2[['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spend_avg = spend_cat_priority2.mean(axis=0).sort_values(ascending=False)\n",
    "spend_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_cat_priority3=df_priority_3[['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_avg = spend_cat_priority3.mean(axis=0).sort_values(ascending=False)\n",
    "spend_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_cat_priority4=df_priority_4[['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_avg = spend_cat_priority4.mean(axis=0).sort_values(ascending=False)\n",
    "spend_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of the Project\n",
    "Leverage the spend behavior and past campaign responses to build a response model that can\n",
    "be used to devise a strategy that enhances the response rates and improves profitability of marketing campaigns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms Used :\n",
    "In this project we have used Logistic Regression, Decision Trees, Random Forests and Gradient Boosting Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Algorithm\n",
    "Among the models that we tried building the GBM Algorithm performed the best in terms of F1_Score and Area under ROC Curve.\n",
    "Therefore we have kept GBM as the final model algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Measures\n",
    "Accuracy - 0.88\n",
    "\n",
    "Precision - 0.75\n",
    "\n",
    "Recall - 0.28\n",
    "\n",
    "F1 Score - 0.41\n",
    "\n",
    "AUC - 0.63\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 drivers from the Model\n",
    "\n",
    "- MntMeatProducts\n",
    "- Income\n",
    "- AcceptedCmp3_1\n",
    "- Customer_Tenure_9\n",
    "- MntFishProducts\n",
    "- NumStorePurchases_2\n",
    "- Marital_Status_Together\n",
    "- NumCatalogPurchases_10\n",
    "- NumCatalogPurchases_6\n",
    "- NumWebPurchases_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best Offers should be provided on the following products\n",
    "- Wines Products\n",
    "- Fish Products\n",
    "- Meat Products\n",
    "- Gold Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
